# =========================================== 
# DOCKER PRODUCTION ENVIRONMENT - Ollama
# ===========================================

# LLM Provider - Set to ollama since you're not using OpenAI
LLM_PROVIDER=ollama

# Ollama Configuration
API_BASE_URL=http://host.docker.internal:11434/v1
MODEL_NAME_AT_ENDPOINT=qwen2.5:1.5b

# Application Settings
PORT=8080
REQUEST_TIMEOUT=30000
NODE_ENV=production

# Logging
LOG_LEVEL=info

# API Endpoints (No keys required)
WEATHER_API_BASE_URL=https://api.open-meteo.com/v1
NEWS_BASE_URL=https://newsapi.org/v2

# Docker/Deployment Settings
HEALTH_CHECK_INTERVAL=30000
CORS_ORIGIN=*

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
